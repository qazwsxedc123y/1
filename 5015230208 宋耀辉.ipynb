import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision
from torchvision import datasets, models, transforms
import numpy as np
import matplotlib.pyplot as plt
import time
import os
import copy
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Subset

# 设置随机种子保证可重复性
torch.manual_seed(42)
np.random.seed(42)

# 检查是否有可用的GPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

## 1. 数据准备和DataLoader创建

# 数据路径 - 需要根据实际情况修改
data_dir = "./data/"

# 定义图像增强和预处理
# 训练集使用数据增强，测试集只做标准化
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),  # 随机裁剪并调整大小
        transforms.RandomHorizontalFlip(),  # 随机水平翻转
        transforms.RandomRotation(15),  # 随机旋转
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 颜色抖动
        transforms.ToTensor(),  # 转换为张量
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # 标准化(ImageNet统计值)
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),  # 调整大小
        transforms.CenterCrop(224),  # 中心裁剪
        transforms.ToTensor(),  # 转换为张量
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # 标准化
    ]),
}

# 加载完整数据集
full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])

# 获取类别名称
class_names = full_dataset.classes
print(f"Class names: {class_names}")

# 划分训练集和测试集(80%训练，20%测试)
train_idx, val_idx = train_test_split(
    list(range(len(full_dataset))), 
    test_size=0.2, 
    shuffle=True, 
    stratify=full_dataset.targets  # 保持类别分布
)

# 创建子集
train_dataset = Subset(full_dataset, train_idx)
val_dataset = Subset(full_dataset, val_idx)

# 修改验证集的transform
for idx in val_idx:
    val_dataset.dataset.transform = data_transforms['val']

# 创建DataLoader
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)

# 查看数据集大小
print(f"Train dataset size: {len(train_dataset)}")
print(f"Validation dataset size: {len(val_dataset)}")

# 可视化一些训练样本
def imshow(inp, title=None):
    """显示张量图像"""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean  # 反标准化
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # 暂停一下让绘图更新

# 获取一批训练数据
inputs, classes = next(iter(train_loader))

# 制作网格并显示
out = torchvision.utils.make_grid(inputs[:4])
imshow(out, title=[class_names[x] for x in classes[:4]])

## 2. 模型选择(VGG或ResNet)和修改

# 我们选择ResNet18作为基础模型
model = models.resnet18(pretrained=True)  # 使用预训练模型

# 冻结所有模型参数(先不训练)
for param in model.parameters():
    param.requires_grad = False

# 替换最后的全连接层以适应我们的分类任务(4类)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_names))

# 将模型移动到GPU
model = model.to(device)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()

# 只优化最后一层的参数
optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)

# 设置学习率衰减策略(每7个epoch衰减为原来的0.1倍)
exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

## 3. 训练函数和评估函数

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    """训练模型并返回训练过程中的指标"""
    since = time.time()

    # 用于保存最佳模型权重
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # 用于记录训练过程中的指标
    train_loss_history = []
    train_acc_history = []
    val_loss_history = []
    val_acc_history = []

    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        # 每个epoch都有训练和验证阶段
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # 设置为训练模式
                dataloader = train_loader
            else:
                model.eval()   # 设置为评估模式
                dataloader = val_loader

            running_loss = 0.0
            running_corrects = 0

            # 迭代数据
            for inputs, labels in dataloader:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # 梯度清零
                optimizer.zero_grad()

                # 前向传播
                # 只在训练时跟踪历史
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # 训练阶段的反向传播和优化
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # 统计指标
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / len(dataloader.dataset)
            epoch_acc = running_corrects.double() / len(dataloader.dataset)

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # 记录指标
            if phase == 'train':
                train_loss_history.append(epoch_loss)
                train_acc_history.append(epoch_acc.cpu().numpy())
            else:
                val_loss_history.append(epoch_loss)
                val_acc_history.append(epoch_acc.cpu().numpy())

            # 深度复制模型(如果是最好的模型)
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val Acc: {best_acc:4f}')

    # 加载最佳模型权重
    model.load_state_dict(best_model_wts)
    
    # 返回模型和训练历史
    return model, {
        'train_loss': train_loss_history,
        'train_acc': train_acc_history,
        'val_loss': val_loss_history,
        'val_acc': val_acc_history
    }

## 4. 训练模型

num_epochs = 15
model, history = train_model(
    model, criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs
)

## 5. 可视化训练过程

plt.figure(figsize=(12, 5))

# 绘制训练和验证的损失
plt.subplot(1, 2, 1)
plt.plot(history['train_loss'], label='Train Loss')
plt.plot(history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# 绘制训练和验证的准确率
plt.subplot(1, 2, 2)
plt.plot(history['train_acc'], label='Train Accuracy')
plt.plot(history['val_acc'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()